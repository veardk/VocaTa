/**
 * VocaTa AIå¯¹è¯ç³»ç»Ÿ - WebSocketå®¢æˆ·ç«¯å’ŒéŸ³é¢‘ç®¡ç†å™¨
 * åŸºäºæ–‡æ¡£ VocaTa-AIå¯¹è¯å®Œæ•´å¯¹æ¥æ–‡æ¡£.md å®ç°
 */

import { getToken } from './token'

// WebSocketæ¶ˆæ¯ç±»å‹å®šä¹‰
interface WebSocketMessage {
  type: string
  [key: string]: any
}

interface STTResultMessage extends WebSocketMessage {
  type: 'stt_result'
  text: string
  isFinal: boolean
  confidence: number
  timestamp: number
}

interface LLMTextStreamMessage extends WebSocketMessage {
  type: 'llm_text_stream'
  text: string
  characterName: string
  isComplete: boolean
  timestamp: number
}

interface TTSAudioMetaMessage extends WebSocketMessage {
  type: 'tts_audio_meta'
  audioSize: number
  format: string
  sampleRate: number
  channels: number
  bitDepth: number
  timestamp: number
}

interface CompleteMessage extends WebSocketMessage {
  type: 'complete'
  message: string
  timestamp: number
}

interface ErrorMessage extends WebSocketMessage {
  type: 'error'
  error: string
  timestamp: number
}

// WebSocketå®¢æˆ·ç«¯ç±»
export class VocaTaWebSocketClient {
  private ws: WebSocket | null = null
  private conversationUuid: string
  private reconnectAttempts = 0
  private readonly maxReconnectAttempts = 5
  private callbacks: Map<string, Function[]> = new Map()

  constructor(conversationUuid: string) {
    this.conversationUuid = conversationUuid
  }

  connect(): void {
    console.log('ğŸ”„ å¼€å§‹å»ºç«‹WebSocketè¿æ¥ï¼ŒconversationUuid:', this.conversationUuid)

    const token = getToken()
    if (!token) {
      console.error('âŒ æœªæ‰¾åˆ°è®¤è¯ä»¤ç‰Œï¼Œæ— æ³•å»ºç«‹WebSocketè¿æ¥')
      this.emit('error', new Error('è®¤è¯ä»¤ç‰Œæœªæ‰¾åˆ°'))
      return
    }

    const wsUrl = `ws://${import.meta.env.VITE_APP_URL.replace('http://', '')}/ws/chat/${this.conversationUuid}?token=${encodeURIComponent(token)}`
    console.log('ğŸ”Œ å°è¯•è¿æ¥WebSocket:', wsUrl)
    console.log('ğŸ” ä½¿ç”¨Token:', token.substring(0, 20) + '...')

    try {
      this.ws = new WebSocket(wsUrl)
      this.setupEventHandlers()
    } catch (error) {
      console.error('âŒ WebSocketè¿æ¥åˆ›å»ºå¤±è´¥:', error)
      this.emit('error', error)
    }
  }

  private setupEventHandlers(): void {
    if (!this.ws) return

    this.ws.onopen = (event) => {
      console.log('âœ… WebSocketè¿æ¥å·²å»ºç«‹')
      console.log('ğŸ” WebSocketçŠ¶æ€æ£€æŸ¥:', {
        readyState: this.ws?.readyState,
        isOpen: this.ws?.readyState === WebSocket.OPEN,
        WebSocketOPEN: WebSocket.OPEN
      })
      this.reconnectAttempts = 0
      this.emit('connected', event)
    }

    this.ws.onmessage = (event) => {
      // æ£€æŸ¥æ˜¯å¦ä¸ºäºŒè¿›åˆ¶éŸ³é¢‘æ•°æ®
      if (event.data instanceof ArrayBuffer) {
        console.log(`ğŸ“¦ æ”¶åˆ°éŸ³é¢‘æ•°æ®(ArrayBuffer): ${event.data.byteLength} bytes`)
        this.emit('audioData', event.data)
        return
      }

      // æ£€æŸ¥æ˜¯å¦ä¸ºBlobéŸ³é¢‘æ•°æ®
      if (event.data instanceof Blob) {
        console.log(`ğŸ“¦ æ”¶åˆ°éŸ³é¢‘æ•°æ®(Blob): ${event.data.size} bytes`)
        // å°†Blobè½¬æ¢ä¸ºArrayBuffer
        event.data.arrayBuffer().then(arrayBuffer => {
          this.emit('audioData', arrayBuffer)
        }).catch(error => {
          console.error('âŒ Blobè½¬ArrayBufferå¤±è´¥:', error)
        })
        return
      }

      // å¦åˆ™æŒ‰JSONæ¶ˆæ¯å¤„ç†
      try {
        const message: WebSocketMessage = JSON.parse(event.data)
        console.log(`ğŸ“¨ æ”¶åˆ°æ¶ˆæ¯:`, message)
        this.emit('message', message)
      } catch (e) {
        console.error('âŒ è§£ææ¶ˆæ¯å¤±è´¥:', event.data)
      }
    }

    this.ws.onclose = (event) => {
      console.log(`ğŸ”Œ WebSocketè¿æ¥å…³é—­: code=${event.code}, reason="${event.reason}", wasClean=${event.wasClean}`)
      this.emit('disconnected', event)
      this.attemptReconnect()
    }

    this.ws.onerror = (error) => {
      console.error('âŒ WebSocketé”™è¯¯:', error)
      console.error('WebSocket readyState:', this.ws?.readyState)
      this.emit('error', error)
    }
  }

  // å‘é€æ–‡å­—æ¶ˆæ¯
  sendTextMessage(text: string): void {
    if (!this.ws || this.ws.readyState !== WebSocket.OPEN) {
      console.error('âŒ WebSocketæœªè¿æ¥')
      return
    }

    const message = {
      type: 'text_message',
      data: { message: text }
    }

    console.log('ğŸ“¤ å‘é€æ–‡å­—æ¶ˆæ¯:', text)
    this.ws.send(JSON.stringify(message))
  }

  // å‘é€éŸ³é¢‘æ•°æ®
  sendAudioData(audioBuffer: ArrayBuffer): void {
    if (!this.ws || this.ws.readyState !== WebSocket.OPEN) {
      return
    }
    this.ws.send(audioBuffer)
  }

  // éŸ³é¢‘å½•åˆ¶æ§åˆ¶
  startAudioRecording(): void {
    if (!this.ws || this.ws.readyState !== WebSocket.OPEN) {
      return
    }
    console.log('ğŸ¤ å‘é€å¼€å§‹å½•éŸ³ä¿¡å·')
    this.ws.send(JSON.stringify({ type: 'audio_start' }))
  }

  stopAudioRecording(): void {
    if (!this.ws || this.ws.readyState !== WebSocket.OPEN) {
      return
    }
    console.log('â¹ï¸ å‘é€åœæ­¢å½•éŸ³ä¿¡å·')
    this.ws.send(JSON.stringify({ type: 'audio_end' }))
  }

  // å‘é€å¿ƒè·³
  sendPing(): void {
    if (!this.ws || this.ws.readyState !== WebSocket.OPEN) {
      return
    }
    this.ws.send(JSON.stringify({ type: 'ping' }))
  }

  // äº‹ä»¶ç›‘å¬å™¨
  on(event: string, callback: Function): void {
    if (!this.callbacks.has(event)) {
      this.callbacks.set(event, [])
    }
    this.callbacks.get(event)?.push(callback)
  }

  private emit(event: string, data?: any): void {
    const callbacks = this.callbacks.get(event)
    if (callbacks) {
      callbacks.forEach(callback => callback(data))
    }
  }

  // è‡ªåŠ¨é‡è¿
  private attemptReconnect(): void {
    if (this.reconnectAttempts < this.maxReconnectAttempts) {
      this.reconnectAttempts++
      const delay = Math.pow(2, this.reconnectAttempts) * 1000
      console.log(`ğŸ”„ å°è¯•é‡è¿ (${this.reconnectAttempts}/${this.maxReconnectAttempts}) - ${delay}mså`)

      setTimeout(() => {
        this.connect()
      }, delay)
    } else {
      console.error('âŒ é‡è¿æ¬¡æ•°å·²è¾¾ä¸Šé™')
      this.emit('reconnectFailed')
    }
  }

  disconnect(): void {
    if (this.ws) {
      this.ws.close()
      this.ws = null
    }
  }

  // è·å–è¿æ¥çŠ¶æ€
  get readyState(): number {
    return this.ws?.readyState || WebSocket.CLOSED
  }

  get isConnected(): boolean {
    return this.ws?.readyState === WebSocket.OPEN
  }
}

// éŸ³é¢‘ç®¡ç†å™¨ç±»
export class AudioManager {
  private audioContext: AudioContext | null = null
  private mediaRecorder: MediaRecorder | null = null
  private audioQueue: ArrayBuffer[] = []
  private isPlaying = false
  private isRecording = false
  private audioStream: MediaStream | null = null

  // VAD (è¯­éŸ³æ´»åŠ¨æ£€æµ‹) ç›¸å…³å±æ€§ - ç®€åŒ–ç‰ˆæœ¬ï¼Œè§£å†³ä¹±å‘é€é—®é¢˜
  private analyser: AnalyserNode | null = null
  private dataArray: Uint8Array | null = null
  private vadThreshold = 40 // ç®€å•éŸ³é‡é˜ˆå€¼
  private isVoiceActive = false
  private consecutiveActiveFrames = 0
  private consecutiveSilenceFrames = 0
  private minActiveFrames = 2 // è¿ç»­2å¸§æ£€æµ‹åˆ°è¯­éŸ³æ‰ç¡®è®¤
  private minSilenceFrames = 5 // è¿ç»­5å¸§é™éŸ³æ‰ç¡®è®¤ç»“æŸ
  // éŸ³é¢‘ç¼“å†²é˜Ÿåˆ—
  private audioBuffer: ArrayBuffer[] = []
  private maxBufferSize = 5 // æœ€å¤§ç¼“å†²5ä¸ªéŸ³é¢‘å—
  private currentWsClient: VocaTaWebSocketClient | null = null

  async initialize(): Promise<void> {
    try {
      console.log('ğŸµ éŸ³é¢‘ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼ˆå»¶è¿Ÿåˆå§‹åŒ–AudioContextï¼‰')
      // ä¸å†åœ¨åˆå§‹åŒ–æ—¶ç«‹å³åˆ›å»ºAudioContextï¼Œè€Œæ˜¯åœ¨éœ€è¦æ—¶æ‰åˆ›å»º
      // è¿™æ ·é¿å…äº†æµè§ˆå™¨çš„å®‰å…¨ç­–ç•¥é™åˆ¶
    } catch (error) {
      console.error('âŒ éŸ³é¢‘ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥:', error)
      throw error
    }
  }

  // å»¶è¿Ÿåˆå§‹åŒ–AudioContextï¼Œåœ¨ç”¨æˆ·äº¤äº’åè°ƒç”¨
  private async ensureAudioContext(): Promise<void> {
    if (!this.audioContext) {
      console.log('ğŸµ å»¶è¿Ÿåˆå§‹åŒ–éŸ³é¢‘ä¸Šä¸‹æ–‡...')
      this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)()

      // æ£€æŸ¥éŸ³é¢‘ä¸Šä¸‹æ–‡çŠ¶æ€
      if (this.audioContext.state === 'suspended') {
        await this.audioContext.resume()
      }

      console.log('âœ… éŸ³é¢‘ä¸Šä¸‹æ–‡åˆå§‹åŒ–æˆåŠŸ')
    }
  }

  async startRecording(wsClient: VocaTaWebSocketClient): Promise<void> {
    try {
      console.log('ğŸ¤ è¯·æ±‚éº¦å…‹é£æƒé™...')
      this.currentWsClient = wsClient

      // ç¡®ä¿AudioContextå·²åˆå§‹åŒ–
      await this.ensureAudioContext()

      // æ£€æŸ¥æµè§ˆå™¨æ”¯æŒæƒ…å†µå’Œå…¼å®¹æ€§å¤„ç†
      console.log('ğŸ” åˆå§‹æµè§ˆå™¨æ£€æŸ¥:', {
        mediaDevices: !!navigator.mediaDevices,
        getUserMedia: !!navigator.getUserMedia,
        webkitGetUserMedia: !!(navigator as any).webkitGetUserMedia,
        mozGetUserMedia: !!(navigator as any).mozGetUserMedia,
        userAgent: navigator.userAgent
      })

      // åˆ›å»ºå®Œæ•´çš„MediaDevices polyfill - å®Œå…¨ç§»é™¤æ‰€æœ‰é™åˆ¶
      if (!navigator.mediaDevices) {
        console.warn('âš ï¸ åˆ›å»ºMediaDeviceså¯¹è±¡')
        navigator.mediaDevices = {
          getUserMedia: function(constraints: MediaStreamConstraints): Promise<MediaStream> {
            // å°è¯•æ‰€æœ‰å¯èƒ½çš„getUserMedia APIå®ç°
            const legacyGetUserMedia = (navigator as any).getUserMedia ||
                                     (navigator as any).webkitGetUserMedia ||
                                     (navigator as any).mozGetUserMedia ||
                                     (navigator as any).msGetUserMedia

            if (!legacyGetUserMedia) {
              console.error('âŒ æµè§ˆå™¨å®Œå…¨ä¸æ”¯æŒgetUserMedia API')
              return Promise.reject(new Error('æµè§ˆå™¨ä¸æ”¯æŒéº¦å…‹é£åŠŸèƒ½'))
            }

            console.log('ğŸ”§ ä½¿ç”¨legacy getUserMedia API')
            return new Promise((resolve, reject) => {
              try {
                legacyGetUserMedia.call(navigator, constraints, resolve, reject)
              } catch (error) {
                console.error('âŒ Legacy getUserMediaè°ƒç”¨å¤±è´¥:', error)
                reject(new Error('æ— æ³•è®¿é—®éº¦å…‹é£è®¾å¤‡'))
              }
            })
          }
        } as MediaDevices
      }

      // å¦‚æœMediaDeviceså­˜åœ¨ä½†getUserMediaä¸å­˜åœ¨ï¼Œç›´æ¥æ·»åŠ 
      if (!navigator.mediaDevices.getUserMedia) {
        console.warn('âš ï¸ æ·»åŠ getUserMediaæ–¹æ³•åˆ°ç°æœ‰MediaDeviceså¯¹è±¡')

        // å°è¯•æ‰€æœ‰å¯èƒ½çš„getUserMedia APIå®ç°
        const legacyGetUserMedia = (navigator as any).getUserMedia ||
                                 (navigator as any).webkitGetUserMedia ||
                                 (navigator as any).mozGetUserMedia ||
                                 (navigator as any).msGetUserMedia

        if (!legacyGetUserMedia) {
          console.error('âŒ æ— æ³•æ‰¾åˆ°ä»»ä½•getUserMediaå®ç°')
          throw new Error('æµè§ˆå™¨ä¸æ”¯æŒéº¦å…‹é£åŠŸèƒ½')
        }

        navigator.mediaDevices.getUserMedia = function(constraints: MediaStreamConstraints): Promise<MediaStream> {
          console.log('ğŸ”§ è°ƒç”¨polyfill getUserMedia')
          return new Promise((resolve, reject) => {
            try {
              legacyGetUserMedia.call(navigator, constraints, resolve, reject)
            } catch (error) {
              console.error('âŒ Polyfill getUserMediaè°ƒç”¨å¤±è´¥:', error)
              reject(new Error('æ— æ³•è®¿é—®éº¦å…‹é£è®¾å¤‡'))
            }
          })
        }
      }

      // å†æ¬¡æ£€æŸ¥ï¼Œä¸åšå®‰å…¨é™åˆ¶
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        console.error('âŒ æ— æ³•åˆ›å»ºéŸ³é¢‘API polyfill')
        throw new Error('æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘åŠŸèƒ½')
      }

      // ç›´æ¥å°è¯•è·å–éº¦å…‹é£æƒé™ï¼Œå®Œå…¨ç§»é™¤æ‰€æœ‰å®‰å…¨æ£€æŸ¥
      console.log('ğŸ” æµè§ˆå™¨ç¯å¢ƒæ£€æŸ¥:', {
        protocol: location.protocol,
        hostname: location.hostname,
        mediaDevices: !!navigator.mediaDevices,
        getUserMedia: !!navigator.mediaDevices?.getUserMedia,
        userAgent: navigator.userAgent.substring(0, 100)
      })

      console.info('âœ… å·²ç§»é™¤æ‰€æœ‰HTTPSå’Œå®‰å…¨ä¸Šä¸‹æ–‡é™åˆ¶ï¼Œå¼ºåˆ¶å…è®¸éŸ³é¢‘è®¿é—®')

      // ç›´æ¥è·å–éº¦å…‹é£æƒé™
      this.audioStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          channelCount: 1,
          sampleRate: 16000,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      })

      // å…³é”®ä¿®å¤ï¼šä¸¥æ ¼éªŒè¯éŸ³é¢‘æµå’ŒéŸ³é¢‘è½¨é“
      const tracks = this.audioStream.getTracks()
      const audioTracks = tracks.filter(track => track.kind === 'audio')
      
      console.log('ğŸ” éŸ³é¢‘æµè¯¦ç»†ä¿¡æ¯:', {
        tracks: this.audioStream.getTracks().length,
        audioTracks: audioTracks.length,
        active: this.audioStream.active,
        trackDetails: tracks.map(track => ({
          kind: track.kind,
          enabled: track.enabled,
          readyState: track.readyState,
          label: track.label
        }))
      })

      // éªŒè¯éŸ³é¢‘è½¨é“å­˜åœ¨ä¸”æœ‰æ•ˆ
      if (audioTracks.length === 0) {
        throw new Error('æœªèƒ½è·å–æœ‰æ•ˆçš„éŸ³é¢‘è½¨é“ï¼Œè¯·æ£€æŸ¥éº¦å…‹é£æƒé™æˆ–è®¾å¤‡è¿æ¥')
      }

      if (!this.audioStream.active) {
        throw new Error('éŸ³é¢‘æµæœªæ¿€æ´»ï¼Œè¯·æ£€æŸ¥éº¦å…‹é£è®¾å¤‡çŠ¶æ€')
      }

      // éªŒè¯éŸ³é¢‘è½¨é“çŠ¶æ€
      const activeAudioTracks = audioTracks.filter(track => track.readyState === 'live')
      if (activeAudioTracks.length === 0) {
        throw new Error('éŸ³é¢‘è½¨é“æœªå°±ç»ªï¼Œè¯·é‡è¯•æˆ–æ£€æŸ¥éº¦å…‹é£æƒé™')
      }

      console.log('âœ… éŸ³é¢‘æµéªŒè¯é€šè¿‡:', {
        audioTracks: activeAudioTracks.length,
        firstTrackLabel: activeAudioTracks[0]?.label || 'unknown'
      })

      // æ£€æŸ¥MediaRecorderæ”¯æŒ
      if (!window.MediaRecorder) {
        console.warn('âš ï¸ MediaRecorderä¸æ”¯æŒï¼Œåˆ›å»ºæ¨¡æ‹Ÿå¯¹è±¡')
        ;(window as any).MediaRecorder = class MockMediaRecorder {
          constructor(stream: any, options?: any) {
            this.stream = stream
            this.ondataavailable = null
          }
          start(timeslice?: number) {
            console.log('æ¨¡æ‹Ÿå½•éŸ³å¼€å§‹')
            setTimeout(() => {
              if (this.ondataavailable) {
                this.ondataavailable({ data: new Blob() })
              }
            }, timeslice || 1000)
          }
          stop() { console.log('æ¨¡æ‹Ÿå½•éŸ³åœæ­¢') }
          static isTypeSupported() { return true }
        }
      }

      // æ£€æŸ¥MediaRecorderæ”¯æŒçš„æ ¼å¼
      let mimeType = 'audio/webm;codecs=opus'
      if (!MediaRecorder.isTypeSupported(mimeType)) {
        mimeType = 'audio/webm'
        if (!MediaRecorder.isTypeSupported(mimeType)) {
          mimeType = 'audio/ogg;codecs=opus'
          if (!MediaRecorder.isTypeSupported(mimeType)) {
            mimeType = 'audio/wav'
            if (!MediaRecorder.isTypeSupported(mimeType)) {
              // æœ€åçš„å…œåº•æ–¹æ¡ˆ
              mimeType = 'audio/mpeg'
              if (!MediaRecorder.isTypeSupported(mimeType)) {
                console.warn('âš ï¸ æœªæ‰¾åˆ°å®Œå…¨æ”¯æŒçš„éŸ³é¢‘æ ¼å¼ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®')
                mimeType = '' // ä½¿ç”¨æµè§ˆå™¨é»˜è®¤æ ¼å¼
              }
            }
          }
        }
      }

      console.log('ğŸµ ä½¿ç”¨éŸ³é¢‘æ ¼å¼:', mimeType)

      // åˆ›å»ºMediaRecorderå®ä¾‹ï¼Œä½¿ç”¨å…¼å®¹æ€§æ›´å¥½çš„é…ç½®
      const mediaRecorderOptions: MediaRecorderOptions = {}
      if (mimeType) {
        mediaRecorderOptions.mimeType = mimeType
      }
      // åªåœ¨æ”¯æŒçš„æƒ…å†µä¸‹è®¾ç½®éŸ³é¢‘æ¯”ç‰¹ç‡
      try {
        if (mimeType && MediaRecorder.isTypeSupported(mimeType)) {
          mediaRecorderOptions.audioBitsPerSecond = 16000
        }
      } catch (e) {
        console.warn('âš ï¸ è®¾ç½®éŸ³é¢‘æ¯”ç‰¹ç‡å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®:', e)
      }

      // åˆ›å»ºMediaRecorderå®ä¾‹å‰è¿›è¡Œæœ€ç»ˆéªŒè¯
      console.log('ğŸ”§ åˆ›å»ºMediaRecorderï¼Œé…ç½®:', mediaRecorderOptions)
      
      try {
        this.mediaRecorder = new MediaRecorder(this.audioStream, mediaRecorderOptions)
        console.log('âœ… MediaRecorderåˆ›å»ºæˆåŠŸ')
      } catch (mediaRecorderError) {
        console.error('âŒ MediaRecorderåˆ›å»ºå¤±è´¥:', mediaRecorderError)
        // å°è¯•ä¸å¸¦é…ç½®åˆ›å»º
        try {
          console.log('ğŸ”„ å°è¯•ä½¿ç”¨é»˜è®¤é…ç½®åˆ›å»ºMediaRecorder...')
          this.mediaRecorder = new MediaRecorder(this.audioStream)
          console.log('âœ… ä½¿ç”¨é»˜è®¤é…ç½®çš„MediaRecorderåˆ›å»ºæˆåŠŸ')
        } catch (fallbackError) {
          console.error('âŒ é»˜è®¤é…ç½®MediaRecorderä¹Ÿå¤±è´¥:', fallbackError)
          throw new Error(`MediaRecorderåˆ›å»ºå¤±è´¥ï¼š${fallbackError.message}`)
        }
      }

      // è®¾ç½®VADéŸ³é¢‘åˆ†æ
      await this.setupVAD()

      this.mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          event.data.arrayBuffer().then(buffer => {
            // ä½¿ç”¨ç®€åŒ–çš„éŸ³é¢‘æ´»åŠ¨æ£€æµ‹
            const hasValidSpeech = this.simpleAudioActivityCheck(buffer)

            if (hasValidSpeech && this.currentWsClient) {
              this.bufferAndSendAudio(buffer)
            }
          })
        }
      }

      this.mediaRecorder.start(500) // æ¯500msè®°å½•ä¸€æ¬¡æ•°æ®ï¼Œå‡å°‘ç½‘ç»œå‹åŠ›
      this.isRecording = true
      console.log('âœ… å¼€å§‹å½•éŸ³ (å·²å¯ç”¨ä¸¥æ ¼çš„éŸ³é¢‘æ´»åŠ¨æ£€æµ‹)')

      // æ³¨æ„ï¼šä¸å†ä½¿ç”¨å¤æ‚çš„VADç›‘æ§ï¼Œç›´æ¥åœ¨ondataavailableä¸­è¿›è¡Œæ£€æµ‹

    } catch (error) {
      console.error('âŒ å½•éŸ³å¯åŠ¨å¤±è´¥:', error)
      throw error
    }
  }

  stopRecording(): void {
    if (this.mediaRecorder && this.isRecording) {
      this.mediaRecorder.stop()
      if (this.audioStream) {
        this.audioStream.getTracks().forEach(track => track.stop())
      }
      this.isRecording = false

      // é‡ç½®VADçŠ¶æ€å’Œç¼“å†²åŒº
      this.isVoiceActive = false
      this.consecutiveActiveFrames = 0
      this.consecutiveSilenceFrames = 0
      this.audioBuffer = []

      // æ¸…ç†èµ„æº
      this.currentWsClient = null

      console.log('â¹ï¸ åœæ­¢å½•éŸ³ï¼ŒVADçŠ¶æ€å·²é‡ç½®')
    }
  }

  async playAudio(audioBuffer: ArrayBuffer): Promise<void> {
    try {
      if (!this.audioContext) {
        await this.initialize()
      }

      const audioData = await this.audioContext!.decodeAudioData(audioBuffer.slice())
      const source = this.audioContext!.createBufferSource()
      source.buffer = audioData

      // æ·»åŠ éŸ³é‡æ§åˆ¶
      const gainNode = this.audioContext!.createGain()
      source.connect(gainNode)
      gainNode.connect(this.audioContext!.destination)

      source.start()
      console.log(`ğŸ”Š æ’­æ”¾éŸ³é¢‘: æ—¶é•¿${audioData.duration.toFixed(2)}ç§’`)

      return new Promise((resolve) => {
        source.onended = () => resolve()
      })
    } catch (error) {
      console.error('âŒ éŸ³é¢‘æ’­æ”¾å¤±è´¥:', error)
    }
  }

  // éŸ³é¢‘é˜Ÿåˆ—ç®¡ç†
  addToQueue(audioBuffer: ArrayBuffer): void {
    this.audioQueue.push(audioBuffer)
    if (!this.isPlaying) {
      this.playQueue()
    }
  }

  private async playQueue(): Promise<void> {
    if (this.audioQueue.length === 0) {
      this.isPlaying = false
      return
    }

    this.isPlaying = true

    try {
      // ç¡®ä¿AudioContextå·²åˆå§‹åŒ–
      await this.ensureAudioContext()
    } catch (error) {
      console.warn('âš ï¸ AudioContextåˆå§‹åŒ–å¤±è´¥ï¼Œè·³è¿‡éŸ³é¢‘æ’­æ”¾:', error)
      this.isPlaying = false
      return
    }

    const audioBuffer = this.audioQueue.shift()!

    try {
      await this.playAudio(audioBuffer)
    } catch (error) {
      console.error('âŒ é˜Ÿåˆ—éŸ³é¢‘æ’­æ”¾å¤±è´¥:', error)
    }

    // æ’­æ”¾ä¸‹ä¸€ä¸ª
    this.playQueue()
  }

  clearQueue(): void {
    this.audioQueue = []
    this.isPlaying = false
    console.log('ğŸ—‘ï¸ æ¸…é™¤éŸ³é¢‘é˜Ÿåˆ—')
  }

  // è·å–éŸ³é‡çº§åˆ«ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰
  getVolumeAnalyzer(): (() => number) | null {
    if (!this.audioStream || !this.audioContext) {
      return null
    }

    const analyser = this.audioContext.createAnalyser()
    const microphone = this.audioContext.createMediaStreamSource(this.audioStream)
    const dataArray = new Uint8Array(analyser.frequencyBinCount)

    microphone.connect(analyser)
    analyser.fftSize = 256

    return () => {
      analyser.getByteFrequencyData(dataArray)
      const average = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length
      return average / 255 // æ ‡å‡†åŒ–åˆ°0-1
    }
  }

  // æ£€æŸ¥éº¦å…‹é£æƒé™
  async checkMicrophonePermission(): Promise<PermissionState> {
    try {
      const result = await navigator.permissions.query({ name: 'microphone' as PermissionName })
      return result.state
    } catch {
      return 'prompt'
    }
  }

  get recording(): boolean {
    return this.isRecording
  }

  get playing(): boolean {
    return this.isPlaying
  }

  // VAD (è¯­éŸ³æ´»åŠ¨æ£€æµ‹) ç›¸å…³æ–¹æ³•
  private async setupVAD(): Promise<void> {
    try {
      if (!this.audioContext || !this.audioStream) {
        console.warn('âš ï¸ AudioContextæˆ–AudioStreamæœªåˆå§‹åŒ–ï¼Œè·³è¿‡VADè®¾ç½®')
        return
      }

      // å†æ¬¡éªŒè¯éŸ³é¢‘æµä¸­æœ‰æœ‰æ•ˆçš„éŸ³é¢‘è½¨é“
      const audioTracks = this.audioStream.getTracks().filter(track => track.kind === 'audio')
      if (audioTracks.length === 0) {
        console.warn('âš ï¸ éŸ³é¢‘æµä¸­æ²¡æœ‰éŸ³é¢‘è½¨é“ï¼Œè·³è¿‡VADè®¾ç½®')
        return
      }

      // æ£€æŸ¥éŸ³é¢‘è½¨é“çŠ¶æ€
      const liveAudioTracks = audioTracks.filter(track => track.readyState === 'live')
      if (liveAudioTracks.length === 0) {
        console.warn('âš ï¸ éŸ³é¢‘è½¨é“æœªæ¿€æ´»ï¼Œè·³è¿‡VADè®¾ç½®')
        return
      }

      console.log('ğŸ”§ å¼€å§‹åˆå§‹åŒ–VADï¼ŒéŸ³é¢‘è½¨é“çŠ¶æ€:', {
        totalTracks: this.audioStream.getTracks().length,
        audioTracks: audioTracks.length,
        liveTracks: liveAudioTracks.length
      })

      // åˆ›å»ºéŸ³é¢‘åˆ†æå™¨
      this.analyser = this.audioContext.createAnalyser()
      this.analyser.fftSize = 1024
      this.analyser.smoothingTimeConstant = 0.3

      // åˆ›å»ºéŸ³é¢‘æº - å¢å¼ºé”™è¯¯å¤„ç†
      console.log('ğŸ”§ åˆ›å»ºMediaStreamSource...')
      const source = this.audioContext.createMediaStreamSource(this.audioStream)
      console.log('âœ… MediaStreamSourceåˆ›å»ºæˆåŠŸ')
      
      source.connect(this.analyser)
      console.log('âœ… éŸ³é¢‘æºå·²è¿æ¥åˆ°åˆ†æå™¨')

      // åˆ›å»ºæ•°æ®æ•°ç»„
      this.dataArray = new Uint8Array(this.analyser.frequencyBinCount)
      console.log('âœ… VADæ•°æ®æ•°ç»„å·²åˆ›å»ºï¼Œé•¿åº¦:', this.dataArray.length)

      console.log('âœ… VADè¯­éŸ³æ´»åŠ¨æ£€æµ‹å·²åˆå§‹åŒ–')
    } catch (error) {
      console.error('âŒ VADåˆå§‹åŒ–å¤±è´¥:', error)
      console.error('âŒ é”™è¯¯è¯¦æƒ…:', {
        errorName: error.name,
        errorMessage: error.message,
        audioContextState: this.audioContext?.state,
        audioStreamActive: this.audioStream?.active,
        audioStreamTracks: this.audioStream?.getTracks().length
      })
      console.warn('âš ï¸ å°†ç»§ç»­å½•éŸ³ï¼Œä½†ä¸è¿›è¡Œè¯­éŸ³æ´»åŠ¨æ£€æµ‹')
      // ä¸æŠ›å‡ºé”™è¯¯ï¼Œè®©å½•éŸ³ç»§ç»­ï¼Œåªæ˜¯æ²¡æœ‰VADåŠŸèƒ½
    }
  }

  /**
   * ç®€åŒ–çš„éŸ³é¢‘æ´»åŠ¨æ£€æµ‹ - åŸºäºéŸ³é‡é˜ˆå€¼å’Œè¿ç»­å¸§æ£€æµ‹
   */
  private simpleAudioActivityCheck(audioBuffer: ArrayBuffer): boolean {
    try {
      const view = new Uint8Array(audioBuffer)

      // åŸºç¡€éªŒè¯
      if (view.length < 100) {
        return false
      }

      // è®¡ç®—å¹³å‡éŸ³é‡
      let sum = 0
      for (let i = 0; i < view.length; i += 4) { // é™é‡‡æ ·å‡å°‘è®¡ç®—é‡
        sum += Math.abs(view[i] - 128)
      }
      const avgVolume = sum / (view.length / 4)

      // ç®€å•é˜ˆå€¼æ£€æµ‹
      const hasVoice = avgVolume > this.vadThreshold

      if (hasVoice) {
        this.consecutiveActiveFrames++
        this.consecutiveSilenceFrames = 0
      } else {
        this.consecutiveActiveFrames = 0
        this.consecutiveSilenceFrames++
      }

      // è¯­éŸ³å¼€å§‹æ£€æµ‹
      if (!this.isVoiceActive && this.consecutiveActiveFrames >= this.minActiveFrames) {
        this.isVoiceActive = true
        console.log('ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹')
        return true
      }

      // è¯­éŸ³æŒç»­æ£€æµ‹
      if (this.isVoiceActive && hasVoice) {
        return true
      }

      // è¯­éŸ³ç»“æŸæ£€æµ‹
      if (this.isVoiceActive && this.consecutiveSilenceFrames >= this.minSilenceFrames) {
        this.isVoiceActive = false
        console.log('ğŸ”‡ æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ')
        return false
      }

      return false

    } catch (error) {
      console.warn('âš ï¸ éŸ³é¢‘æ£€æµ‹å¤±è´¥:', error)
      return false
    }
  }

  /**
   * æ™ºèƒ½éŸ³é¢‘ç¼“å†²å’Œå‘é€ç­–ç•¥
   */
  private bufferAndSendAudio(audioBuffer: ArrayBuffer): void {
    // å°†éŸ³é¢‘æ·»åŠ åˆ°ç¼“å†²åŒº
    this.audioBuffer.push(audioBuffer)

    // å¦‚æœç¼“å†²åŒºæ»¡äº†ï¼Œç§»é™¤æœ€è€çš„æ•°æ®
    if (this.audioBuffer.length > this.maxBufferSize) {
      this.audioBuffer.shift()
    }

    // è¯­éŸ³å¼€å§‹æ—¶ï¼Œç«‹å³å‘é€å½“å‰ç¼“å†²åŒºçš„æ‰€æœ‰æ•°æ®
    if (!this.isVoiceActive) {
      console.log('ğŸ¤ è¯­éŸ³å¼€å§‹ï¼Œæ‰¹é‡å‘é€ç¼“å†²éŸ³é¢‘')
      this.flushAudioBuffer()
    } else {
      // è¯­éŸ³æŒç»­æœŸé—´ï¼Œç›´æ¥å‘é€
      console.log(`ğŸµ å‘é€éŸ³é¢‘: ${audioBuffer.byteLength} bytes`)
      this.currentWsClient?.sendAudioData(audioBuffer)
    }
  }

  /**
   * å‘é€ç¼“å†²åŒºä¸­çš„æ‰€æœ‰éŸ³é¢‘æ•°æ®
   */
  private flushAudioBuffer(): void {
    if (this.audioBuffer.length > 0 && this.currentWsClient) {
      console.log(`ğŸ“¤ å‘é€ç¼“å†²éŸ³é¢‘: ${this.audioBuffer.length} ä¸ªç‰‡æ®µ`)

      this.audioBuffer.forEach((buffer, index) => {
        // æŒ‰é¡ºåºå‘é€ï¼Œé¿å…ç½‘ç»œæ‹¥å¡
        setTimeout(() => {
          this.currentWsClient?.sendAudioData(buffer)
        }, index * 50) // æ¯ä¸ªç‰‡æ®µé—´éš”50ms
      })

      this.audioBuffer = []
    }
  }

  // VADé…ç½®æ–¹æ³•
  configureVAD(threshold: number, minActive: number, minSilence: number): void {
    this.vadThreshold = Math.max(20, Math.min(100, threshold))
    this.minActiveFrames = Math.max(1, minActive)
    this.minSilenceFrames = Math.max(2, minSilence)

    console.log(`âš™ï¸ VADé…ç½®æ›´æ–°: é˜ˆå€¼=${this.vadThreshold}, æœ€å°æ´»è·ƒå¸§=${this.minActiveFrames}, æœ€å°é™éŸ³å¸§=${this.minSilenceFrames}`)
  }
}

// å®æ—¶AIå¯¹è¯ç®¡ç†å™¨
export class VocaTaAIChat {
  private wsClient: VocaTaWebSocketClient | null = null
  private audioManager: AudioManager
  private isAudioCallActive = false
  private currentConversation: any = null
  private currentCharacter: any = null

  // ä¸´æ—¶æ¶ˆæ¯å­˜å‚¨ï¼Œç”¨äºæµå¼æ˜¾ç¤º
  private currentLLMResponse = ''
  private currentSTTText = ''

  // å›è°ƒå‡½æ•°
  private onMessageCallback?: (message: any) => void
  private onSTTResultCallback?: (text: string, isFinal: boolean) => void
  private onLLMStreamCallback?: (text: string, isComplete: boolean, characterName?: string) => void
  private onAudioPlayCallback?: (isPlaying: boolean) => void
  private onConnectionStatusCallback?: (status: 'connected' | 'disconnected' | 'error', message?: string) => void

  constructor() {
    this.audioManager = new AudioManager()
  }

  async initialize(conversationUuid: string): Promise<void> {
    try {
      console.log('ğŸš€ åˆå§‹åŒ–AIå¯¹è¯ç³»ç»Ÿ...')

      // åˆå§‹åŒ–éŸ³é¢‘ç®¡ç†å™¨
      await this.audioManager.initialize()

      // å»ºç«‹WebSocketè¿æ¥å¹¶ç­‰å¾…è¿æ¥æˆåŠŸ
      await this.connectWebSocket(conversationUuid)

      console.log('âœ… AIå¯¹è¯ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ')
    } catch (error) {
      console.error('âŒ AIå¯¹è¯ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥:', error)
      throw error
    }
  }

  private connectWebSocket(conversationUuid: string): Promise<void> {
    return new Promise((resolve, reject) => {
      this.wsClient = new VocaTaWebSocketClient(conversationUuid)
      let connectionResolved = false // é˜²æ­¢é‡å¤resolve

      // è®¾ç½®äº‹ä»¶ç›‘å¬å™¨
      this.wsClient.on('connected', () => {
        console.log('ğŸ‰ WebSocketè¿æ¥æˆåŠŸï¼Œç­‰å¾…æœåŠ¡å™¨ç¡®è®¤...')
        // ä¸åœ¨è¿™é‡Œresolveï¼Œç­‰å¾…æœåŠ¡å™¨çŠ¶æ€æ¶ˆæ¯
      })

      this.wsClient.on('message', (message: WebSocketMessage) => {
        this.handleWebSocketMessage(message)

        // å¦‚æœæ”¶åˆ°çŠ¶æ€æ¶ˆæ¯è¡¨ç¤ºè¿æ¥å·²å»ºç«‹ï¼Œåˆ™resolve
        if (!connectionResolved && message.type === 'status' &&
          (message.message?.includes('è¿æ¥å·²å»ºç«‹') || message.message?.includes('WebSocketè¿æ¥å·²å»ºç«‹'))) {
          console.log('ğŸ‰ æ”¶åˆ°æœåŠ¡å™¨è¿æ¥ç¡®è®¤ï¼Œè¿æ¥å®Œå…¨å»ºç«‹')
          connectionResolved = true
          this.onConnectionStatusCallback?.('connected', 'WebSocketè¿æ¥å·²å»ºç«‹')
          resolve()
        }

        // å¦‚æœè¿˜æ²¡æœ‰è¿æ¥ç¡®è®¤ï¼Œä½†æ”¶åˆ°äº†ä»»ä½•å…¶ä»–æ¶ˆæ¯ï¼ˆAIå›å¤ç­‰ï¼‰ï¼Œä¹Ÿè®¤ä¸ºè¿æ¥æˆåŠŸ
        if (!connectionResolved && (message.type === 'llm_text_stream' || message.type === 'text_message')) {
          console.log('ğŸ¯ æ”¶åˆ°AIæ¶ˆæ¯ï¼Œè¿æ¥ç¡®è®¤æˆåŠŸ')
          connectionResolved = true
          this.onConnectionStatusCallback?.('connected', 'AIç³»ç»Ÿè¿æ¥æˆåŠŸ')
          resolve()
        }
      })

      this.wsClient.on('audioData', (audioBuffer: ArrayBuffer) => {
        this.handleAudioData(audioBuffer)
      })

      this.wsClient.on('error', (error: any) => {
        console.error('âŒ WebSocketé”™è¯¯:', error)
        this.onConnectionStatusCallback?.('error', 'WebSocketè¿æ¥é”™è¯¯')
        if (!connectionResolved) {
          connectionResolved = true
          reject(error)
        }
      })

      this.wsClient.on('disconnected', () => {
        console.log('ğŸ“¡ WebSocketè¿æ¥æ–­å¼€ï¼Œæ­£åœ¨é‡è¿...')
        this.onConnectionStatusCallback?.('disconnected', 'è¿æ¥å·²æ–­å¼€ï¼Œæ­£åœ¨é‡è¿...')
      })

      this.wsClient.on('reconnectFailed', () => {
        console.error('âŒ WebSocketé‡è¿å¤±è´¥')
        this.onConnectionStatusCallback?.('error', 'è¿æ¥å¤±è´¥ï¼Œè¯·åˆ·æ–°é¡µé¢é‡è¯•')
      })

      // å¯åŠ¨è¿æ¥
      this.wsClient.connect()

      // è®¾ç½®è¶…æ—¶ï¼Œå¦‚æœ10ç§’å†…æ²¡æœ‰è¿æ¥æˆåŠŸï¼Œåˆ™reject
      setTimeout(() => {
        if (!connectionResolved) {
          console.error('âŒ WebSocketè¿æ¥è¶…æ—¶')
          connectionResolved = true
          reject(new Error('WebSocketè¿æ¥è¶…æ—¶'))
        }
      }, 10000)
    })
  }

  private handleWebSocketMessage(message: WebSocketMessage): void {
    switch (message.type) {
      case 'stt_result':
        this.handleSTTResult(message as STTResultMessage)
        break

      case 'llm_text_stream':
        this.handleLLMTextStream(message as LLMTextStreamMessage)
        break

      case 'tts_audio_meta':
        this.handleTTSAudioMeta(message as TTSAudioMetaMessage)
        break

      case 'complete':
        this.handleProcessComplete(message as CompleteMessage)
        break

      case 'error':
        this.handleError(message as ErrorMessage)
        break

      default:
        console.log('ğŸ”„ æ”¶åˆ°å…¶ä»–ç±»å‹æ¶ˆæ¯:', message)
    }

    // è§¦å‘é€šç”¨æ¶ˆæ¯å›è°ƒ
    this.onMessageCallback?.(message)
  }

  private handleSTTResult(message: STTResultMessage): void {
    console.log(`ğŸ¤ STTè¯†åˆ«: ${message.text} (${message.isFinal ? 'æœ€ç»ˆ' : 'ä¸´æ—¶'})`)

    this.currentSTTText = message.text
    this.onSTTResultCallback?.(message.text, message.isFinal)
  }

  private handleLLMTextStream(message: LLMTextStreamMessage): void {
    console.log(`ğŸ¤– LLMå“åº”: ${message.text} (${message.isComplete ? 'å®Œæˆ' : 'æµå¼'})`)

    // ä¿®å¤ï¼šå§‹ç»ˆç´¯ç§¯æ–‡æœ¬ï¼Œæ— è®ºæ˜¯å¦å®Œæˆ
    // æµå¼æ¸²æŸ“åº”è¯¥ç´¯ç§¯æ‰€æœ‰æ”¶åˆ°çš„æ–‡æœ¬ç‰‡æ®µ
    this.currentLLMResponse += message.text

    console.log(`ğŸ” å½“å‰ç´¯ç§¯æ–‡æœ¬é•¿åº¦: ${this.currentLLMResponse.length}`)

    this.onLLMStreamCallback?.(this.currentLLMResponse, message.isComplete, message.characterName)

    if (message.isComplete) {
      this.currentLLMResponse = '' // é‡ç½®
    }
  }

  private handleTTSAudioMeta(message: TTSAudioMetaMessage): void {
    console.log(`ğŸ”Š TTSéŸ³é¢‘å…ƒæ•°æ®: ${message.audioSize} bytes, ${message.format}`)
  }

  private handleAudioData(audioBuffer: ArrayBuffer): void {
    console.log(`ğŸ”Š æ’­æ”¾éŸ³é¢‘æ•°æ®: ${audioBuffer.byteLength} bytes`)
    this.audioManager.addToQueue(audioBuffer)
    this.onAudioPlayCallback?.(true)
  }

  private handleProcessComplete(message: CompleteMessage): void {
    console.log('âœ… å¤„ç†å®Œæˆ:', message.message)
  }

  private handleError(message: ErrorMessage): void {
    console.error('âŒ æœåŠ¡å™¨é”™è¯¯:', message.error)
  }

  // å…¬å¼€æ–¹æ³•
  sendTextMessage(text: string): void {
    if (!this.wsClient) {
      console.error('âŒ WebSocketå®¢æˆ·ç«¯æœªåˆå§‹åŒ–')
      return
    }

    this.wsClient.sendTextMessage(text)
  }

  async startAudioCall(): Promise<void> {
    try {
      this.isAudioCallActive = true
      console.log('ğŸ“ å¼€å§‹éŸ³é¢‘é€šè¯')

      await this.audioManager.startRecording(this.wsClient!)
      this.wsClient?.startAudioRecording()

    } catch (error) {
      console.error('âŒ æ— æ³•å¯åŠ¨éŸ³é¢‘é€šè¯:', error)
      this.isAudioCallActive = false
      throw error
    }
  }

  stopAudioCall(): void {
    console.log('ğŸ“ åœæ­¢éŸ³é¢‘é€šè¯')
    this.isAudioCallActive = false

    this.audioManager.stopRecording()
    this.audioManager.clearQueue()
    this.wsClient?.stopAudioRecording()

    this.onAudioPlayCallback?.(false)
  }

  // è®¾ç½®å›è°ƒå‡½æ•°
  onMessage(callback: (message: any) => void): void {
    this.onMessageCallback = callback
  }

  onSTTResult(callback: (text: string, isFinal: boolean) => void): void {
    this.onSTTResultCallback = callback
  }

  onLLMStream(callback: (text: string, isComplete: boolean, characterName?: string) => void): void {
    this.onLLMStreamCallback = callback
  }

  onAudioPlay(callback: (isPlaying: boolean) => void): void {
    this.onAudioPlayCallback = callback
  }

  onConnectionStatus(callback: (status: 'connected' | 'disconnected' | 'error', message?: string) => void): void {
    this.onConnectionStatusCallback = callback
  }

  // è·å–çŠ¶æ€
  get connected(): boolean {
    const isConnected = this.wsClient?.isConnected || false
    console.log('ğŸ” æ£€æŸ¥è¿æ¥çŠ¶æ€:', {
      wsClient: !!this.wsClient,
      readyState: this.wsClient?.readyState,
      isConnected: isConnected,
      expectedReadyState: WebSocket.OPEN
    })
    return isConnected
  }

  get audioCallActive(): boolean {
    return this.isAudioCallActive
  }

  get recording(): boolean {
    return this.audioManager.recording
  }

  get playing(): boolean {
    return this.audioManager.playing
  }

  // æ¸…ç†èµ„æº
  destroy(): void {
    console.log('ğŸ§¹ æ¸…ç†AIå¯¹è¯ç³»ç»Ÿèµ„æº')

    this.stopAudioCall()
    this.wsClient?.disconnect()
    this.audioManager.clearQueue()

    this.wsClient = null
    this.onMessageCallback = undefined
    this.onSTTResultCallback = undefined
    this.onLLMStreamCallback = undefined
    this.onAudioPlayCallback = undefined
    this.onConnectionStatusCallback = undefined
  }
}